= The OpenVX(TM) OpenCL(TM) Interop Extension
:regtitle: pass:q,r[^Â®^]
Editor: Radhakrishna Giduthuri; The Khronos{regtitle} OpenVX Working Group V 1.0 (provisional), 25th January 2018:
:doctype: book
:data-uri:
:title-logo-image: images/Khronos_RGB.svg
:source-highlighter: highlight.js
:encoding: utf-8
:lang: en
:toc: left
:toclevels: 3
:numbered:
:icons: font
:autofit-option:
:halfimagewidth: width="200"
:ubar: _
:star: *
:chapter-label:

image:images/OpenVX_500px_June16.png[align="center",{halfimagewidth}]

include::copyright-spec.txt[]

<<<

Technical Contributors::
 - Radhakrishna Giduthuri, AMD
 - Niclas Danielsson, Axis Communications AB
 - Thierry Lepley, Cadence
 - Frank Brill, Cadence
 - John MacCallum, Imagination
 - Ben Ashbaugh, Intel
 - Adam Herr, Intel

== Introduction
[[VX_MEMORY_TYPE_HOST,VX_MEMORY_TYPE_HOST]] [[vx_bool,vx_bool]] [[vx_false_e,vx_false_e]] [[vx_true_e,vx_true_e]] [[vxFinalizeKernel,vxFinalizeKernel]] [[vx_kernel_initialize_f,vx_kernel_initialize_f]] [[vx_kernel_deinitialize_f,vx_kernel_deinitialize_f]] [[vx_kernel_f,vx_kernel_f]] [[vx_memory_type_e,vx_memory_type_e]] [[vxCopyImagePatch,vxCopyImagePatch]] [[vxMapImagePatch,vxMapImagePatch]] [[vxCreateContext,vxCreateContext]] [[VX_TYPE_INVALID,VX_TYPE_INVALID]] [[VX_SUCCESS,VX_SUCCESS]] [[VX_ERROR_INVALID_REFERENCE,VX_ERROR_INVALID_REFERENCE]] [[VX_ERROR_INVALID_FORMAT,VX_ERROR_INVALID_FORMAT]] [[VX_ERROR_INVALID_GRAPH,VX_ERROR_INVALID_GRAPH]] [[VX_ERROR_INVALID_NODE,VX_ERROR_INVALID_NODE]] [[VX_ERROR_INVALID_PARAMETERS,VX_ERROR_INVALID_PARAMETERS]] [[VX_ERROR_INVALID_SCOPE,VX_ERROR_INVALID_SCOPE]] [[VX_ERROR_INVALID_TYPE,VX_ERROR_INVALID_TYPE]] [[VX_ERROR_INVALID_VALUE,VX_ERROR_INVALID_VALUE]] [[VX_ERROR_NO_MEMORY,VX_ERROR_NO_MEMORY]] [[VX_ERROR_NO_RESOURCES,VX_ERROR_NO_RESOURCES]] [[VX_ERROR_NOT_COMPATIBLE,VX_ERROR_NOT_COMPATIBLE]] [[VX_ERROR_NOT_ALLOCATED,VX_ERROR_NOT_ALLOCATED]] [[VX_ERROR_NOT_IMPLEMENTED,VX_ERROR_NOT_IMPLEMENTED]] [[VX_ERROR_NOT_SUFFICIENT,VX_ERROR_NOT_SUFFICIENT]] [[VX_ERROR_NOT_SUPPORTED,VX_ERROR_NOT_SUPPORTED]] [[VX_ERROR_OPTIMIZED_AWAY,VX_ERROR_OPTIMIZED_AWAY]] [[VX_ERROR_INVALID_DIMENSION,VX_ERROR_INVALID_DIMENSION]] [[vx_node,vx_node]] [[vx_int32,vx_int32]] [[vxHarrisCornersNode,vxHarrisCornersNode]] [[vxVerifyGraph,vxVerifyGraph]] [[vxQueryReference,vxQueryReference]] [[vx_uint8,vx_uint8]] [[vx_size,vx_size]] [[vxCreateGenericNode,vxCreateGenericNode]] [[vx_enum,vx_enum]] [[vx_char,vx_char]] [[vx_reference,vx_reference]] [[vxReleaseReference,vxReleaseReference]] [[vxCreateImageFromHandle,vxCreateImageFromHandle]] [[vxSetNodeTarget,vxSetNodeTarget]] [[vxHint,vxHint]] [[vxSetGraphParameterByIndex,vxSetGraphParameterByIndex]] [[vxGetStatus,vxGetStatus]] [[vxSetParameterByIndex,vxSetParameterByIndex]] [[vx_image,vx_image]] [[vx_lut,vx_lut]] [[vx_convolution,vx_convolution]] [[vx_delay,vx_delay]] [[vx_distribution,vx_distribution]] [[vx_pyramid,vx_pyramid]] [[vx_threshold,vx_threshold]] [[vx_array,vx_array]] [[vx_object_array,vx_object_array]] [[vx_remap,vx_remap]] [[vx_tensor,vx_tensor]] [[vx_matrix,vx_matrix]] [[vx_scalar,vx_scalar]] [[vxSetReferenceName,vxSetReferenceName]] [[vxSwapImageHandle,vxSwapImageHandle]] [[vx_kernel,vx_kernel]] [[vx_graph,vx_graph]] [[vx_status,vx_status]] [[vx_context,vx_context]] [[vxProcessGraph,vxProcessGraph]] [[vxScheduleGraph,vxScheduleGraph]] [[vxWaitGraph,vxWaitGraph]] [[VX_TYPE_OBJECT_ARRAY,VX_TYPE_OBJECT_ARRAY]] [[vx_uint32,vx_uint32]] [[VX_ERROR_GRAPH_ABANDONED,VX_ERROR_GRAPH_ABANDONED]] This document details an extension to OpenVX 1.2, and references some APIs and symbols that may be found in that API, at https://www.khronos.org/registry/OpenVX/specs/1.2/html/index.html.

[[cl_command_queue,cl_command_queue]] [[cl_program,cl_program]] [[cl_device_id,cl_device_id]] [[cl_context,cl_context]] [[cl_mem,cl_mem]] Refer to the OpenCL 1.2 specification at https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/.

The name of this extension is *_vx_khr_opencl_interop_*.

=== Purpose
This OpenVX extension provides a mechanism for interoperation between an OpenVX implementation and an OpenCL application/user-kernel.
Efficient communication is key to successful interoperation.  The data exchange mechanism needs features such that:
[circle]
 - OpenCL data objects can be imported into the OpenVX environment
 - OpenVX data objects can be accessed as OpenCL data objects
 - fully asynchronous host-device operations are enabled during data exchange

=== Features of the extension specification
This interop extension supports six essential features.
[circle]
 - share common `<<cl_context>>` object between OpenVX and the OpenCL application
 - share a set of common in-order `<<cl_command_queue>>` objects for coordination between OpenVX and the OpenCL application/user-kernel
 - mechanism for an OpenCL application to export `<<cl_mem>>` buffers to OpenVX
 - mechanism for an OpenCL application to reclaim exported `<<cl_mem>>` buffers back from OpenVX
 - mechanism for an OpenCL application/user-kernel to temporarily map OpenVX data objects into `<<cl_mem>>` buffers
 - mechanism to copy between `<<cl_mem>>` buffers and OpenVX data objects.

=== Preserve the asynchronous property of OpenCL
OpenCL has an asynchronous host API where command queues are executed asynchronously unless
the application issues a blocking command.
A `<<cl_mem>>` buffer is a handle to an opaque OpenCL data object. OpenCL kernels that consume such data
objects can be enqueued into a command queue _before_ the command that produces the
content of this data object starts executing. This asynchronous property of the OpenCL API
is fundamental, since it allows hiding various overheads/latencies such as creating OpenCL objects
or launching kernels on an accelerator. The _vx_khr_opencl_interop_ API intends
to preserve this asynchronous property by avoiding unnecessary host-accelerator synchronizations when the ownership of
data objects switch between OpenCL and OpenVX, or when data are copied between OpenCL
and OpenVX.

There are two actors in the _vx_khr_opencl_interop_ API:
[circle]
 - the application/user-kernel that uses OpenCL in addition to OpenVX
 - the OpenVX implementation

When a `<<cl_mem>>` buffer is imported into OpenVX or when an OpenVX object is mapped as an OpenCL object,
the ownership of the related data object temporarily changes from one actor to the other.
Since the actual production of the data object content is considered as asynchronous, the actor
that gets the ownership of the data object can't assume the data content is available.
It then has two alternatives:
[circle]
- launch asynchronous tasks (such as OpenCL kernels), making sure that these tasks will
  not start executing before the tasks of the other actor that produces the data object
  content are complete.
- wait until the data is ready before executing a synchronous task that consumes the content
  of the data object

To ensure the proper coordination between the two actors that exchange data objects, the
_vx_khr_opencl_interop_ API relies on an OpenCL command queue, referred to in this document as a
*_coordination command queue_*.
A _coordination command queue_ is the contract between the two actors exchanging the ownership
of the data object. It allows both producer and consumer actors to make sure that
any data production task of the former `<<cl_mem>>` owner actor is executed before any data
consumption tasks of the new owner actor.
The _coordination command queue_ enables this coordination to happen asynchronously while still
supporting synchronization if this is the choice of one of the actors.

=== Coordination Command Queues
There are two types of _coordination command queues_:
[circle]
 - A unique *global* _coordination command queue_ for coordination between the application OpenCL workload
   and the OpenVX implementation, outside of OpenVX graphs. The application can provide the
   global _coordination command queue_ when creating the OpenVX context using the `<<vxCreateContextFromCL>>` API;
   otherwise it will be created by the OpenVX implementation.
 - *User node* _coordination command queues_ for coordination between the user nodes and the
   OpenVX implementation. These _coordination command queues_ will be created and managed by the
   OpenVX implementation. An OpenVX implementation may use one or more command queues across
   all the user nodes. The `<<VX_NODE_CL_COMMAND_QUEUE>>` node attribute can be queried
   from within `<<vx_kernel_initialize_f>>`, `<<vx_kernel_f>>`, and `<<vx_kernel_deinitialize_f>>` callbacks,
   to get access to a user node's _coordination command queue_.

When ownership of an OpenCL object changes from actor A (producer of data) to
actor B (consumer of data), the Actor A must make sure that its tasks producing the exchanged `<<cl_mem>>` buffers
are enqueued into the _coordination command queue_ before the ownership change.

Note:
In OpenCL, command queues are associated with a target device. In the context of the _vx_khr_opencl_interop_ API,
the device to which the _coordination command queue_ is associated is not important,
since it does not prevent actors from using other command queues targeting other devices.
The application can manage any dependencies between command queues using OpenCL markers
(or barriers) and events.


=== Usage Example of the _vx_khr_opencl_interop_ API

In this example, OpenVX is used to process an image provided by a camera in the host memory.
Then OpenCL is used to post-process the two outputs of the OpenVX graph on different OpenCL
devices. The example goes through the following steps:

[circle]
 - create a `<<vx_context>>` using a `<<cl_context>>` supplied by the application
 - create multiple `<<cl_mem>>` buffers for the input capture device to cycle through
 - create graph output images using `<<vxCreateImageFromHandle>>()` with
   the memory type as `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>`
 - import a pre-verified OpenVX graph
 - execute the OpenVX graph
 - reclaim the OpenCL buffer and enqueue post-processing OpenCL kernels

[source,cpp]
----
#include <VX/vx_khr_opencl_interop.h>

  ...
  // Create an OpenCL context with two OpenCL devices.
  cl_context_properties ctxprop[] = {
      CL_CONTEXT_PLATFORM, (cl_context_properties)platform_id, 0, 0
  };
  cl_device_id device_list[2] = { device_id1, device_id2 };
  cl_context opencl_context;
  opencl_context = clCreateContext(ctxprop, 2, device_list, NULL, NULL, NULL);

  // Create in-order command queues for two different compute devices.
  cl_command_queue global_command_queue, second_command_queue;
  global_command_queue = clCreateCommandQueue(opencl_context, device_id1, 0, NULL);
  second_command_queue = clCreateCommandQueue(opencl_context, device_id2, 0, NULL);

  // Compile and get the OpenCL kernels.
  cl_program opencl_program = clCreateProgramWithSource(opencl_context, 1,
                                    (const char **) &KernelSource, NULL, NULL);
  clBuildProgram(opencl_program, 2, device_list, NULL, NULL, NULL);
  cl_kernel opencl_kernel1 = clCreateKernel(opencl_program, "my_kernel1", NULL);
  cl_kernel opencl_kernel2 = clCreateKernel(opencl_program, "my_kernel2", NULL);

  // Allocate OpenCL buffers.
  cl_mem opencl_buf1 = clCreateBuffer(opencl_context, CL_MEM_READ_WRITE, 640*480,
                                        NULL, NULL);
  cl_mem opencl_buf2 = clCreateBuffer(opencl_context, CL_MEM_READ_WRITE, 640*480,
                                        NULL, NULL);

  // Create the OpenVX context by specifying the OpenCL context and
  // the global coordination command queue.
  vx_context context = vxCreateContextFromCL(opencl_context, global_command_queue);

  // Get data input data from the camera capture API.
  void *camera_buffer = getBufferFromCamera();

  // Create the OpenVX input image (from camera host memory buffer).
  vx_imagepatch_addressing_t addr = {
      640, 480, 1, 640, VX_SCALE_UNITY, VX_SCALE_UNITY, 1, 1
  };
  vx_image input = vxCreateImageFromHandle(context, VX_DF_IMAGE_U8, &addr,
        &camera_buffer, VX_MEMORY_HOST);

  // Create OpenVX output images (from the opencl buffers).
  vx_image output1 = vxCreateImageFromHandle(context,
      VX_DF_IMAGE_U8, &addr, &opencl_buf1, VX_MEMORY_TYPE_OPENCL_BUFFER);
  vx_image output2 = vxCreateImageFromHandle(context,
      VX_DF_IMAGE_U8, &addr, &opencl_buf2, VX_MEMORY_TYPE_OPENCL_BUFFER);

  // Import a pre-verified OpenVX graph from memory at 'ptr' and size of 'len' bytes.
  vx_reference refs[4] = { NULL, input, output1, output2 };
  vx_enum uses[4] = {
        VX_IX_USE_EXPORT_VALUES,      // graph
        VX_IX_USE_APPLICATION_CREATE, // input
        VX_IX_USE_APPLICATION_CREATE, // output1
        VX_IX_USE_APPLICATION_CREATE  // output2
  };
  vx_import import = vxImportObjectsFromMemory(context, 4, refs, uses, ptr, len);
  vx_graph graph = (vx_graph)refs[0];

  // Execute the OpenVX graph.
  vxProcessGraph(graph);

  // Reclaim the OpenCL buffers for some post-processing. The OpenVX workload to write
  // into these buffers may still be pending with the global coordination command queue
  vxSwapImageHandle(output1, NULL, &opencl_buf1, 1);
  vxSwapImageHandle(output2, NULL, &opencl_buf2, 1);

  // Buffers can be used directly with the global command queue if target used is the same.
  // Below kernel1 will be scheduled on device_id1 using the global command queue.
  {
    clSetKernelArg(kernel1, 0, sizeof(cl_mem), (void *)&opencl_buf1);
    size_t localWorkSize[2] = { 16, 16 };
    size_t globalWorkSize[2] = { 640, 480 };
    clEnqueueNDRangeKernel(global_command_queue, kernel1, 2, NULL,
        globalWorkSize, localWorkSize, 0, NULL, NULL)
  }

  // To use buffer with another command queue that has a different target device from
  // the global coordination command queue, a sync point needs to be used. The code below uses
  // a marker and an event to sync between two command queues and make sure
  // that the second command queue waits for the global coordination command queue.
  // Then kernel2 is scheduled on device_id2 using a second command queue.
  {
    cl_event event;
    clEnqueueMarker(global_command_queue, &event);
    clSetKernelArg(kernel2, 0, sizeof(cl_mem), (void *)&opencl_buf2);
    size_t localWorkSize[2] = { 1, 1 };
    size_t globalWorkSize[2] = { 640, 480 };
    clEnqueueNDRangeKernel(second_command_queue, kernel2, 2, NULL,
        globalWorkSize, localWorkSize, 1, &event, NULL);
  }
  ...
----

== Additional Functionality of Existing OpenVX APIs
This extension defines only one new API function (`<<vxCreateContextFromCL>>`), but modifies and extends
several existing OpenVX APIs. This section summarizes the extension of the existing APIs.

=== Global OpenCL context
The `<<vxCreateContext>>()` function is extended to create a OpenCL context that can be queried
using a new `<<VX_CONTEXT_CL_CONTEXT>>` attribute of `<<vx_context>>`.
Alternatively, the new `<<vxCreateContextFromCL>>` function can be used to create
an OpenVX context with a specific global OpenCL context.

=== Global Coordination Command Queue
The `<<vxCreateContext>>()` function is extended to create the in-order global _coordination command queue_
that can be queried using a new `<<VX_CONTEXT_CL_COMMAND_QUEUE>>` attribute of `<<vx_context>>`.
Alternatively, the new `<<vxCreateContextFromCL>>` function can be used to create
an OpenVX context with a specific in-order global OpenCL command queue. The command queue
must be in the specified global OpenCL context.

=== User kernels and nodes

==== User kernel using the _vx_khr_opencl_interop_ extension

A user-defined kernel that makes use of the _vx_khr_opencl_interop_ extension
must be declared by setting the `<<VX_KERNEL_USE_OPENCL>>` kernel attribute to `<<vx_true_e>>`
at kernel registration time before calling `<<vxFinalizeKernel>>`.
This attribute is read-only after the `<<vxFinalizeKernel>>` call.

==== User node _coordination command queue_

Only user nodes created from user kernels declared as `<<VX_KERNEL_USE_OPENCL>>` can use
the _vx_khr_opencl_interop_ API. The _coordination command queue_ is given by the
OpenVX implementation and must be queried by the user node using the `<<VX_NODE_CL_COMMAND_QUEUE>>`
node attribute.

The value of `<<VX_NODE_CL_COMMAND_QUEUE>>` must be set by the OpenVX implementation prior to calling
the `<<vx_kernel_initialize_f>>` callback and it must not change until the `<<vx_kernel_deinitialize_f>>`
callback is invoked.

=== OpenCL buffer memory type
A new `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>` enum for `<<vx_memory_type_e>>` is accepted by the following APIs:
[circle]
 - all __vxCreateXxxxFromHandle__ APIs, such as, `<<vxCreateImageFromHandle>>()`
 - all __vxCopyXxxx__ APIs, such as, `<<vxCopyImagePatch>>()`
 - all __vxMapXxxx__ APIs, such as, `<<vxMapImagePatch>>()`

The __vxCreateXxxxFromHandle__ APIs and corresponding __vxSwapXxxx__ APIs accept `<<cl_mem>>` buffers
in `ptrs` when `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>` is used
[circle]
 - The  caller (i.e., the application) must make sure that the content of the `<<cl_mem>>` buffer is available to
   any command enqueued into the _coordination command queue_ at the time the
   __vxCreateXxxxFromHandle__ APIs are called
 - The contents of reclaimed `<<cl_mem>>` buffers are available to any command enqueued into the _coordination
   command queue_ after the __vxSwapXxxx__ call returns.

The __vxCopyXxxx__ APIs accept `<<cl_mem>>` buffers as the `user_ptr` when `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>` is used.
[circle]
 - if __vxCopyXxxx__ is called in read mode, the data copied into the user `<<cl_mem>>` buffer is available
   to any command enqueued into the _coordination command queue_ after the vxCopyXxxx call returns.
 - if __vxCopyXxxx__ is called in write mode, the caller (the application) must make sure that the
   content of the user `<<cl_mem>>` buffer is available to any command enqueued into the _coordination command
   queue_ at the time the __vxCopyXxxx__ function is called

The __vxMapXxxx__ APIs returns a `<<cl_mem>>` buffer in `ptr` when `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>` is used.
Subsequently, __vxUnmapXxxx__ will accept a `<<cl_mem>>` buffer as `ptr` when `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>`
was used for the corresponding __vxMapXxxx__ operation.
[circle]
 - if  __vxMapXxxx__ is requested in read-only mode or read/write mode, the content of the returned `<<cl_mem>>`
   buffer is available to any command enqueued into the _coordination command queue_ after
   the __vxMapXxxx__ call returns.
 - if  __vxMapXxxx__ is requested in write-only mode or read/write mode, the caller (the application) must
   make sure that the content of the returned `<<cl_mem>>` buffer is available to any command enqueued into
   the _coordination command queue_ at the time the corresponding __vxUnmapXxxx__ call is performed.

Any data object can be mapped or copied using `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>` or `<<VX_MEMORY_TYPE_HOST>>`.

== Constants
[[VX_NODE_CL_COMMAND_QUEUE,VX_NODE_CL_COMMAND_QUEUE]] [[VX_MEMORY_TYPE_OPENCL_BUFFER,VX_MEMORY_TYPE_OPENCL_BUFFER]] [[VX_KERNEL_USE_OPENCL,VX_KERNEL_USE_OPENCL]] [[VX_CONTEXT_CL_CONTEXT,VX_CONTEXT_CL_CONTEXT]] [[VX_CONTEXT_CL_COMMAND_QUEUE,VX_CONTEXT_CL_COMMAND_QUEUE]] The following constants are declared in the header file __ VX/vx_khr_opencl_interop.h __:

indexterm:[VX_CONTEXT_CL_CONTEXT,definition]
indexterm:[VX_MEMORY_TYPE_OPENCL_BUFFER,definition]
indexterm:[VX_NODE_CL_COMMAND_QUEUE,definition]
indexterm:[VX_CONTEXT_CL_COMMAND_QUEUE,definition]
indexterm:[VX_KERNEL_USE_OPENCL,definition]

.Constants introduced by this extension
[cols=".^5,.^6",options="header"]
|===
s| Name s| Use
| `<<VX_CONTEXT_CL_CONTEXT>>`           | `<<vx_context>>` attribute to query the OpenCL context associated with the OpenVX context. Read-only.
| `<<VX_MEMORY_TYPE_OPENCL_BUFFER>>`    | The `<<vx_memory_type_e>>` enum to import from the OpenCL buffer.
| `<<VX_CONTEXT_CL_COMMAND_QUEUE>>`     | `<<vx_context>>` attribute to query the _coordination command queue_ associated with the OpenVX context. Read-only.
| `<<VX_NODE_CL_COMMAND_QUEUE>>`        | `<<vx_node>>` attribute to query the `<<cl_command_queue>>` associated with a user kernel node. Read-only.
| `<<VX_KERNEL_USE_OPENCL>>`            | `<<vx_kernel>>` attribute to specify and query whether a user kernel is using the _vx_khr_opencl_interop_ API. Return value is `<<vx_bool>>`. The default value of this attribute is `<<vx_false_e>>`. This attribute is read-only after the `<<vxFinalizeKernel>>` call.
|===

== The OpenCL Interop API functions

indexterm:[OpenCL Interop API, vxCreateContextFromCL]

=== vxCreateContextFromCL
Create an OpenVX context with specified OpenCL context and global _coordination command queue_.

include::api/protos/vxCreateContextFromCL.txt[]

[horizontal]
.Parameters
opencl_context:: [in] The OpenCL context
opencl_command_queue:: [in] The global _coordination command queue_

.Return Value
 - On success, a valid `<<vx_context>>` object. Calling `<<vxGetStatus>>` with the return value as a parameter will return VX_SUCCESS if the function was successful.

****
An implementation may provide several different error codes to give useful diagnostic information in the event of failure to create the context.
****

.Description
This function creates a top-level object context for OpenVX and uses the OpenCL context and global _coordination command queue_ created by the application for the interop.

This OpenCL context and global _coordination command queue_ can be queried using the `<<VX_CONTEXT_CL_CONTEXT>>` and `<<VX_CONTEXT_CL_COMMAND_QUEUE>>` attributes of `<<vx_context>>`.

If the OpenVX context is created using `<<vxCreateContext>>` or
`<<vxCreateContextFromCL>>` with `opencl_context` as NULL,
the OpenCL context used by OpenVX is implementation dependent.
If the `opencl_command_queue` is NULL,
the global _coordination command queue_ used by OpenVX is implementation dependent.

The global _coordination command queue_ must be created using the OpenCL context used by OpenVX.

ifdef::backend-pdf[]
[index]
== Index
////////////////////////////////////////////////////////////////
The index is normally left completely empty, it's contents being
generated automatically by the DocBook toolchain.
////////////////////////////////////////////////////////////////
endif::[]
